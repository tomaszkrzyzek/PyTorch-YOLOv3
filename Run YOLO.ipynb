{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn\n",
    "import torch.utils.data\n",
    "import torch.hub\n",
    "import torch.optim\n",
    "import torchvision.transforms\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import utils.datasets\n",
    "\n",
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class YOLO(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, bounding_box_shape):\n",
    "        super(YOLO, self).__init__()\n",
    "        output_size = bounding_box_shape[0] * bounding_box_shape[1]\n",
    "        self.convolution = torch.hub.load('pytorch/vision:v0.4.2', 'resnet18', pretrained=True)\n",
    "        self.bounding_box = torch.nn.Sequential(\n",
    "            torch.nn.Dropout(),\n",
    "            torch.nn.Linear(in_features=1000, out_features=4000),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout(p=0.5),\n",
    "            torch.nn.Linear(in_features=4000, out_features=4000),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout(p=0.5),\n",
    "            torch.nn.Linear(in_features=4000, out_features=output_size),\n",
    "        )\n",
    "        self.bounding_box_shape = bounding_box_shape\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.convolution(x)\n",
    "        x = self.bounding_box(x)\n",
    "        breakpoint()\n",
    "        x = torch.reshape(x, shape=self.bounding_box_shape)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_TEST = '../data-science-bowl-2018/stage1_test'\n",
    "PATH_TO_TRAIN = '../data-science-bowl-2018/stage1_train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from ../data-science-bowl-2018/stage1_train...\n",
      "Loading masks...\n",
      "Loading from ../data-science-bowl-2018/stage1_train...\n",
      "Loading masks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read masks::   0%|          | 2/670 [00:00<00:41, 16.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 670 masks\n",
      "Loaded 670 masks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read masks:: 100%|██████████| 670/670 [03:04<00:00,  3.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data done!\n"
     ]
    }
   ],
   "source": [
    "train = utils.datasets.PandasDataset(PATH_TO_TRAIN, augment=True, multiscale=True,normalized_labels=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = utils.datasets.PandasDataset(PATH_TO_TEST, augment=False, multiscale=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/kruszylo/.cache/torch/hub/pytorch_vision_v0.4.2\n",
      "Using cache found in /Users/kruszylo/.cache/torch/hub/pytorch_vision_v0.4.2\n"
     ]
    }
   ],
   "source": [
    "#because each batch is a single tensor (matrix) \n",
    "#and pytorch is saying that all the images \n",
    "#in a batch need to be the same size\n",
    "batch_size = 1#128\n",
    "learning_rate = 0.0001\n",
    "epoch = 30\n",
    "\n",
    "bounding_box_shape = (3, 3, 7)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True)\n",
    "# test_loader = torch.utils.data.DataLoader(test, batch_size=batch_size)\n",
    "\n",
    "model = YOLO(bounding_box_shape).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "loss_function = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "Training:   0%|          | 0/29461 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0\n",
      "Epoch:  0\n",
      "> <ipython-input-20-1f5961551314>(23)forward()\n",
      "-> x = torch.reshape(x, shape=self.bounding_box_shape)\n",
      "> <ipython-input-20-1f5961551314>(23)forward()\n",
      "-> x = torch.reshape(x, shape=self.bounding_box_shape)\n",
      "(Pdb) x.shape\n",
      "torch.Size([1, 9])\n",
      "torch.Size([1, 9])\n",
      "(Pdb) x\n",
      "tensor([[ 0.1769,  0.1079, -0.1357, -0.0677, -0.3508,  0.3863, -0.0590,  0.2838,\n",
      "         -0.0392]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.1769,  0.1079, -0.1357, -0.0677, -0.3508,  0.3863, -0.0590,  0.2838,\n",
      "         -0.0392]], grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "for epoch_number in range(epoch):\n",
    "    print(\"Epoch: \", epoch_number)\n",
    "\n",
    "    model.train()\n",
    "    for _img_path, x, y in tqdm(train_loader, desc=\"Training: \"):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(x)\n",
    "        loss_value = loss_function(output, y)\n",
    "        loss_value.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    test_loss = 0\n",
    "\n",
    "#     with torch.no_grad():\n",
    "#         for x, y in tqdm(test_loader, desc='Evaluate: '):\n",
    "#             x, y = x.to(device), y.to(device)\n",
    "#             output = model(x)\n",
    "#             test_loss += np.mean(loss_function(output, y).item())\n",
    "\n",
    "#         print('\\nLoss value: {}'.format(test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
